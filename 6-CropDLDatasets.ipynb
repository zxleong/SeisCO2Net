{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As discussed in the paper, we stacked the datasets into sets of 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sklearn.preprocessing as pp\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d\n",
    "from scipy.signal import triang\n",
    "import torch\n",
    "from torch import nn\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import decimate\n",
    "from scipy import interpolate\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.matlib import repmat\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO2_Maps = np.load('data/co2maps/co2_maps.npy')\n",
    "Seismic_Gathers = np.load('data/seismic_gathers/seismic_gathers.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination\n",
    "\n",
    "#split first\n",
    "X_main_npa,X_test_npa,y_main_npa,y_test_npa = train_test_split(Seismic_Gathers,CO2_Maps,test_size=0.05,random_state=155)\n",
    "X_train_npa,X_valid_npa,y_train_npa,y_valid_npa = train_test_split(X_main_npa,y_main_npa,test_size=0.05,random_state=155)\n",
    "\n",
    "idx_array = np.arange(20)\n",
    "comb_list = np.array(list(combinations(idx_array,10)))\n",
    "np.random.seed(155)\n",
    "X_train_np = []; y_train_np = []\n",
    "X_valid_np = []; y_valid_np = [] \n",
    "X_test_np = []; y_test_np = []\n",
    "\n",
    "#do training data\n",
    "for i in tqdm(range(len(X_train_npa))):\n",
    "    stemp = []; ctemp = []\n",
    "    Ncomb = 300\n",
    "    idx_comb = np.arange(len(comb_list))\n",
    "    Ncomb_list = np.random.choice(idx_comb,size=Ncomb,replace=False)\n",
    "    for j in range(Ncomb):\n",
    "        selected_comb_idx = Ncomb_list[j]\n",
    "        selected_comb = comb_list[selected_comb_idx]\n",
    "        sp1 = X_train_npa[i,selected_comb]\n",
    "        cp1 = y_train_npa[i,selected_comb] \n",
    "        stemp.append(sp1)\n",
    "        ctemp.append(cp1)\n",
    "    stemp = np.array(stemp)\n",
    "    ctemp = np.array(ctemp)\n",
    "    X_train_np.append(stemp)\n",
    "    y_train_np.append(ctemp)\n",
    "X_train_np = np.array(X_train_np)\n",
    "y_train_np = np.array(y_train_np)\n",
    "\n",
    "#do validation data\n",
    "for i in tqdm(range(len(X_valid_npa))):\n",
    "    stemp = []; ctemp = []\n",
    "    Ncomb = 500\n",
    "    idx_comb = np.arange(len(comb_list))\n",
    "    Ncomb_list = np.random.choice(idx_comb,size=Ncomb,replace=False)\n",
    "    for j in range(Ncomb):\n",
    "        selected_comb_idx = Ncomb_list[j]\n",
    "        selected_comb = comb_list[selected_comb_idx]\n",
    "        sp1 = X_valid_npa[i,selected_comb]\n",
    "        cp1 = y_valid_npa[i,selected_comb] \n",
    "        stemp.append(sp1)\n",
    "        ctemp.append(cp1)\n",
    "    stemp = np.array(stemp)\n",
    "    ctemp = np.array(ctemp)\n",
    "    X_valid_np.append(stemp)\n",
    "    y_valid_np.append(ctemp)\n",
    "X_valid_np = np.array(X_valid_np)\n",
    "y_valid_np = np.array(y_valid_np)\n",
    "\n",
    "\n",
    "#do testing data\n",
    "for i in tqdm(range(len(X_test_npa))):\n",
    "    stemp = []; ctemp = []\n",
    "    Ncomb = 500\n",
    "    idx_comb = np.arange(len(comb_list))\n",
    "    Ncomb_list = np.random.choice(idx_comb,size=Ncomb,replace=False)\n",
    "    for j in range(Ncomb):\n",
    "        selected_comb_idx = Ncomb_list[j]\n",
    "        selected_comb = comb_list[selected_comb_idx]\n",
    "        sp1 = X_test_npa[i,selected_comb]\n",
    "        cp1 = y_test_npa[i,selected_comb] \n",
    "        stemp.append(sp1)\n",
    "        ctemp.append(cp1)\n",
    "    stemp = np.array(stemp)\n",
    "    ctemp = np.array(ctemp)\n",
    "    X_test_np.append(stemp)\n",
    "    y_test_np.append(ctemp)\n",
    "X_test_np = np.array(X_test_np)\n",
    "y_test_np = np.array(y_test_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train_np.reshape(X_train_np.shape[0]*X_train_np.shape[1],X_train_np.shape[2],X_train_np.shape[3],X_train_np.shape[4])\n",
    "y_train_np = y_train_np.reshape(y_train_np.shape[0]*y_train_np.shape[1],y_train_np.shape[2],y_train_np.shape[3],y_train_np.shape[4])\n",
    "X_valid_np = X_valid_np.reshape(X_valid_np.shape[0]*X_valid_np.shape[1],X_valid_np.shape[2],X_valid_np.shape[3],X_valid_np.shape[4])\n",
    "y_valid_np = y_valid_np.reshape(y_valid_np.shape[0]*y_valid_np.shape[1],y_valid_np.shape[2],y_valid_np.shape[3],y_valid_np.shape[4])\n",
    "X_test_np = X_test_np.reshape(X_test_np.shape[0]*X_test_np.shape[1],X_test_np.shape[2],X_test_np.shape[3],X_test_np.shape[4])\n",
    "y_test_np = y_test_np.reshape(y_test_np.shape[0]*y_test_np.shape[1],y_test_np.shape[2],y_test_np.shape[3],y_test_np.shape[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/crop_DLdatasets/exF_comb_X_train.npy',X_train_np)\n",
    "np.save('data/crop_DLdatasets/exF_comb_X_valid.npy',X_valid_np)\n",
    "np.save('data/crop_DLdatasets/exF_comb_y_train.npy',y_train_np)\n",
    "np.save('data/crop_DLdatasets/exF_comb_y_valid.npy',y_valid_np)\n",
    "np.save('data/crop_DLdatasets/exF_comb_X_test.npy',X_test_np)\n",
    "np.save('data/crop_DLdatasets/exF_comb_y_test.npy',y_test_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
